{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest # 特征选择\n",
    "from sklearn.feature_selection import chi2 # 卡方统计量\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler # 数据归一化\n",
    "from sklearn.decomposition import PCA # 主成分分析\n",
    "from sklearn.model_selection import GridSearchCV # 网格搜索交叉验证,用于选择最优的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 设置属性防止中文乱码\n",
    "mpl.rcParams['font.sans-serif'] = [u'SimHei']\n",
    "mpl.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore',category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_feature_E = 'sepal length', 'sepal width', 'petal length', 'petal width'\n",
    "iris_feature_C = '花萼长度', '花萼宽度', '花瓣长度', '花瓣宽度'\n",
    "iris_class = 'Iris-setosa', 'Iris-versicolor', 'Iris-virginica'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总样本数目: 150 ; 特征属性数目: 4\n",
      "     0    1    2    3\n",
      "0  5.1  3.5  1.4  0.2\n",
      "1  4.9  3.0  1.4  0.2\n",
      "2  4.7  3.2  1.3  0.2\n",
      "3  4.6  3.1  1.5  0.2\n",
      "4  5.0  3.6  1.4  0.2\n",
      "<class 'numpy.ndarray'>\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# 读取数据,查看数据\n",
    "data=pd.read_csv(\"datas/iris.data\",header=None)\n",
    "# 获取X变量\n",
    "x=data[[0,1,2,3]]\n",
    "y=pd.Categorical(data[4]).codes\n",
    "print(\"总样本数目: %d ; 特征属性数目: %d\" % x.shape)\n",
    "print(x.head())\n",
    "print(type(y))\n",
    "print(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集,测试集划分\n",
    "x_train1,x_test1,y_train1,y_test1=train_test_split(x,y,test_size=0.2,random_state=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据集样本数目: 120,测试数据集样本数目: 30\n",
      "int64\n",
      "[0 1 1 0 1 0 2 1 2 1]\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test=x_train1,x_test1,y_train1,y_test1\n",
    "print(\"训练数据集样本数目: %d,测试数据集样本数目: %d\" % (x_train.shape[0],x_test.shape[0]))\n",
    "\n",
    "# 决策树的叶子节点的目标值必须是数值型变量\n",
    "y_train=y_train.astype(np.int)\n",
    "y_test=y_test.astype(np.int)\n",
    "\n",
    "print(y_train.dtype)\n",
    "print(y_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据标准化\n",
    "\n",
    "## StandardScaler (基于特征矩阵的列,将属性值转换至服从正态分布)\n",
    "\n",
    "1. 标准化是依照特征矩阵的列处理数据,其通过求z-score的方法,将样本的特征值转换到同一量纲下\n",
    "2. 常用于基于正态分布的算法,比如回归算法\n",
    "\n",
    "# 数据归一化\n",
    "\n",
    "## MinMaxScaler(区间缩放,基于最大最小值,将数据转换到0,1区间上的)\n",
    "\n",
    "1. 提升模型收敛速度,提升模型精度\n",
    "2. 常见于神经网络\n",
    "\n",
    "# Normalizer(基于矩阵的行,将样本向量转换为单位向量)\n",
    "\n",
    "1. 其目的在于样本向量在点乘运算或其他核函数计算相似性时,拥有统一的标准\n",
    "2. 常见用于文本分类和聚类,logistic回归中也会使用,有效防止过拟合\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数据各个特征属性的调整最小值: [0. 0. 0.]\n",
      "原始数据各个特征属性的缩放数据值: [1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "ss=MinMaxScaler()\n",
    "# sklearn 中模型API说明:\n",
    "# fit : 模型训练,基于给定的训练集(X,Y)训练出一个模型;该API是没有返回值的.eg:ss.fit(X_train,Y_train)执行后,ss这个模型对象就训练好了.\n",
    "# transfrom : 数据转换,使用训练好的模型对给定的数据集(X) 进行转换操作;一般如果训练集进行转换操作,那么测试集也需要转换操作;这个API只在特征工程中出现\n",
    "# predict : 数据转换/数据预测,功能和transfrom一样,都是对给定的数据集x进行转换操作,只是transfrom中返回的是一个新的x,而predict返回的是预测值;这个API只在算法模型中出现\n",
    "# fit_transfrom : fit+transfrom两个API的合并,表示先根据给定的数据训练模型(fit),然后使用训练好的模型对给定的数据进行转换操作\n",
    "x_train=ss.fit_transform(x_train)\n",
    "\n",
    "x_test=ss.transform(x_test)\n",
    "\n",
    "print(\"原始数据各个特征属性的调整最小值:\",ss.min_)\n",
    "print(\"原始数据各个特征属性的缩放数据值:\",ss.scale_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对类别判断影响最大的三个特征属性分布是: [ True False  True  True]\n",
      "[0 2 3]\n"
     ]
    }
   ],
   "source": [
    "# 特征选择: 从已有的特征中选择出影响目标值最大的特征属性\n",
    "# 常用方法:\n",
    "# 分类:F统计量,卡方系数,互信息mutual_info_classif\n",
    "# 连续:皮尔逊相关系数,F统计量,互信息mutual_info_classif\n",
    "\n",
    "# SelectKBest(卡方系数)\n",
    "# 在当前的案例中,使用SelectKBest这个方法从4个原始特征属性,选择出来3个\n",
    "ch2=SelectKBest(chi2,k=3)\n",
    "# k默认为10,如果指定了k,那么就会返回指定的特征个数\n",
    "x_train=ch2.fit_transform(x_train,y_train) # 训练并转换\n",
    "x_test=ch2.transform(x_test) # 转换\n",
    "\n",
    "select_name_index=ch2.get_support(indices=True)\n",
    "print(\"对类别判断影响最大的三个特征属性分布是:\",ch2.get_support(indices=False))\n",
    "print(select_name_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22222222, 0.06896552, 0.04166667],\n",
       "       [0.19444444, 0.37931034, 0.375     ],\n",
       "       [0.5       , 0.62068966, 0.45833333],\n",
       "       [0.41666667, 0.01724138, 0.04166667],\n",
       "       [0.36111111, 0.48275862, 0.41666667],\n",
       "       [0.33333333, 0.03448276, 0.04166667],\n",
       "       [0.44444444, 0.68965517, 0.70833333],\n",
       "       [0.33333333, 0.46551724, 0.41666667],\n",
       "       [0.47222222, 0.67241379, 0.58333333],\n",
       "       [0.58333333, 0.5862069 , 0.58333333],\n",
       "       [0.80555556, 0.84482759, 0.70833333],\n",
       "       [0.22222222, 0.0862069 , 0.04166667],\n",
       "       [0.38888889, 0.06896552, 0.125     ],\n",
       "       [0.41666667, 0.48275862, 0.45833333],\n",
       "       [0.58333333, 0.72413793, 0.75      ],\n",
       "       [0.5       , 0.77586207, 0.54166667],\n",
       "       [0.16666667, 0.06896552, 0.        ],\n",
       "       [0.02777778, 0.05172414, 0.04166667],\n",
       "       [0.02777778, 0.03448276, 0.04166667],\n",
       "       [0.55555556, 0.56896552, 0.5       ],\n",
       "       [0.19444444, 0.05172414, 0.04166667],\n",
       "       [0.19444444, 0.0862069 , 0.125     ],\n",
       "       [0.94444444, 0.96551724, 0.79166667],\n",
       "       [0.66666667, 0.70689655, 0.91666667],\n",
       "       [0.66666667, 0.62068966, 0.58333333],\n",
       "       [0.55555556, 0.77586207, 0.95833333],\n",
       "       [0.41666667, 0.68965517, 0.75      ],\n",
       "       [0.33333333, 0.05172414, 0.04166667],\n",
       "       [0.38888889, 0.5862069 , 0.5       ],\n",
       "       [0.61111111, 0.75862069, 0.70833333],\n",
       "       [0.36111111, 0.43103448, 0.5       ],\n",
       "       [0.5       , 0.60344828, 0.54166667],\n",
       "       [0.5       , 0.65517241, 0.70833333],\n",
       "       [0.47222222, 0.5862069 , 0.625     ],\n",
       "       [0.22222222, 0.32758621, 0.41666667],\n",
       "       [0.80555556, 0.81034483, 0.625     ],\n",
       "       [0.44444444, 0.63793103, 0.70833333],\n",
       "       [0.69444444, 0.63793103, 0.54166667],\n",
       "       [0.38888889, 0.51724138, 0.5       ],\n",
       "       [0.36111111, 0.53448276, 0.5       ],\n",
       "       [0.55555556, 0.65517241, 0.58333333],\n",
       "       [0.47222222, 0.5       , 0.375     ],\n",
       "       [0.47222222, 0.68965517, 0.625     ],\n",
       "       [0.61111111, 0.68965517, 0.79166667],\n",
       "       [0.66666667, 0.77586207, 0.95833333],\n",
       "       [0.19444444, 0.01724138, 0.04166667],\n",
       "       [0.27777778, 0.06896552, 0.04166667],\n",
       "       [0.52777778, 0.63793103, 0.70833333],\n",
       "       [0.25      , 0.05172414, 0.04166667],\n",
       "       [0.61111111, 0.70689655, 0.79166667],\n",
       "       [0.08333333, 0.06896552, 0.04166667],\n",
       "       [0.13888889, 0.0862069 , 0.04166667],\n",
       "       [0.58333333, 0.72413793, 0.91666667],\n",
       "       [0.72222222, 0.65517241, 0.58333333],\n",
       "       [0.30555556, 0.03448276, 0.125     ],\n",
       "       [0.75      , 0.62068966, 0.54166667],\n",
       "       [0.72222222, 0.74137931, 0.83333333],\n",
       "       [0.66666667, 0.79310345, 0.83333333],\n",
       "       [0.36111111, 0.65517241, 0.79166667],\n",
       "       [0.19444444, 0.4137931 , 0.375     ],\n",
       "       [0.47222222, 0.5862069 , 0.58333333],\n",
       "       [0.91666667, 0.94827586, 0.83333333],\n",
       "       [0.58333333, 0.55172414, 0.5       ],\n",
       "       [0.69444444, 0.82758621, 0.91666667],\n",
       "       [0.86111111, 0.86206897, 0.75      ],\n",
       "       [0.55555556, 0.84482759, 1.        ],\n",
       "       [0.22222222, 0.06896552, 0.125     ],\n",
       "       [1.        , 0.9137931 , 0.79166667],\n",
       "       [0.38888889, 0.4137931 , 0.375     ],\n",
       "       [0.55555556, 0.62068966, 0.625     ],\n",
       "       [0.        , 0.        , 0.        ],\n",
       "       [0.58333333, 0.77586207, 0.875     ],\n",
       "       [0.33333333, 0.44827586, 0.375     ],\n",
       "       [0.66666667, 0.67241379, 0.66666667],\n",
       "       [0.63888889, 0.56896552, 0.54166667],\n",
       "       [0.16666667, 0.37931034, 0.375     ],\n",
       "       [0.66666667, 0.56896552, 0.54166667],\n",
       "       [0.22222222, 0.06896552, 0.08333333],\n",
       "       [0.13888889, 0.0862069 , 0.04166667],\n",
       "       [0.13888889, 0.05172414, 0.08333333],\n",
       "       [0.30555556, 0.06896552, 0.04166667],\n",
       "       [0.5       , 0.62068966, 0.54166667],\n",
       "       [0.61111111, 0.81034483, 0.875     ],\n",
       "       [0.55555556, 0.67241379, 0.75      ],\n",
       "       [0.16666667, 0.05172414, 0.04166667],\n",
       "       [0.41666667, 0.68965517, 0.95833333],\n",
       "       [0.19444444, 0.0862069 , 0.20833333],\n",
       "       [0.33333333, 0.56896552, 0.45833333],\n",
       "       [0.94444444, 0.96551724, 0.875     ],\n",
       "       [0.25      , 0.06896552, 0.04166667],\n",
       "       [0.25      , 0.48275862, 0.54166667],\n",
       "       [0.16666667, 0.06896552, 0.        ],\n",
       "       [0.30555556, 0.06896552, 0.125     ],\n",
       "       [0.58333333, 0.75862069, 0.70833333],\n",
       "       [0.94444444, 1.        , 0.91666667],\n",
       "       [0.58333333, 0.77586207, 0.83333333],\n",
       "       [0.22222222, 0.05172414, 0.08333333],\n",
       "       [0.94444444, 0.86206897, 0.91666667],\n",
       "       [0.55555556, 0.65517241, 0.70833333],\n",
       "       [0.52777778, 0.5862069 , 0.58333333],\n",
       "       [0.41666667, 0.51724138, 0.375     ],\n",
       "       [0.05555556, 0.03448276, 0.08333333],\n",
       "       [0.41666667, 0.68965517, 0.75      ],\n",
       "       [0.72222222, 0.79310345, 0.91666667],\n",
       "       [0.16666667, 0.06896552, 0.        ],\n",
       "       [0.55555556, 0.68965517, 0.58333333],\n",
       "       [0.30555556, 0.5862069 , 0.58333333],\n",
       "       [0.22222222, 0.05172414, 0.04166667],\n",
       "       [0.66666667, 0.79310345, 1.        ],\n",
       "       [0.19444444, 0.05172414, 0.04166667],\n",
       "       [0.25      , 0.06896552, 0.        ],\n",
       "       [0.19444444, 0.0862069 , 0.04166667],\n",
       "       [0.80555556, 0.86206897, 1.        ],\n",
       "       [0.44444444, 0.53448276, 0.58333333],\n",
       "       [0.47222222, 0.63793103, 0.70833333],\n",
       "       [0.77777778, 0.82758621, 0.83333333],\n",
       "       [0.5       , 0.5       , 0.5       ],\n",
       "       [0.13888889, 0.05172414, 0.        ],\n",
       "       [0.36111111, 0.51724138, 0.5       ],\n",
       "       [0.83333333, 0.89655172, 0.70833333]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 降维:对于数据而言,如果特征属性比较多,在构建过程中,会比较复杂,这个时候考虑将多维(高维)映射到低维的数据\n",
    "# 常用的方法:\n",
    "# PCA:主成分分析(无监督)\n",
    "# LDA:线性判别分析(有监督)类内方差最小,人脸识别,通常先做一次pca\n",
    "pca=PCA(n_components=2) # 构建一个pca对象,设置最终维度是2维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}